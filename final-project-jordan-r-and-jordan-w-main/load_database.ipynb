{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a2d7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DWTS Final Project\n",
    "# Course: DAT153\n",
    "# Term: Spring 2025\n",
    "# Author: Jordan Whitehouse & Jordan Reed\n",
    "# Script: Database Population Script\n",
    "\n",
    "# Database connection and setup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String, Date, Boolean, Text\n",
    "import os\n",
    "import openpyxl\n",
    "\n",
    "# Set up PostgreSQL connection\n",
    "host = 'localhost'\n",
    "dbname = 'dwts'\n",
    "user = 'postgres'      \n",
    "password = 'DaisyJohnson084*' \n",
    "port = 5432\n",
    "\n",
    "# Connect to postgresSQL\n",
    "engine = create_engine(f\"postgresql://postgres:DaisyJohnson084*@localhost:5432/dwts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd001e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Excel data\n",
    "\n",
    "# Path to my dwts excel file (update path depending on where file is)\n",
    "excel_path = \"C:\\\\Users\\\\16159\\\\OneDrive - Davidson College\\\\Desktop\\\\Semester 6- Spring 2024\\\\DAT153\\\\final-project-jordan-r-and-jordan-w-main\\\\New_dwts.xlsx\"\n",
    "\n",
    "#Load dwts sheets\n",
    "celeb_info_df = pd.read_excel(excel_path, sheet_name=\"celeb_info\")\n",
    "judges_scores_df = pd.read_excel(excel_path, sheet_name=\"judge_scores\")\n",
    "judges_df = pd.read_excel(excel_path, sheet_name=\"judges\")\n",
    "hosts_df = pd.read_excel(excel_path, sheet_name=\"hosts\")\n",
    "dance_styles_df = pd.read_excel(excel_path, sheet_name=\"dance_styles\")\n",
    "season_info_df = pd.read_excel(excel_path, sheet_name=\"season_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "818694da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load celebrity tables\n",
    "\n",
    "celeb_df = celeb_info_df[['celebrity_name', 'celebrity_industry', 'celebrity_homestate', 'celebrity_homecountry', 'celebrity_age_during_season', 'season']].copy()\n",
    "\n",
    "# Drop duplicates (to handle returnees from earlier seasons)\n",
    "celebrity_unique = celeb_df[['celebrity_name', 'celebrity_industry', 'celebrity_homestate', 'celebrity_homecountry']].drop_duplicates()\n",
    "\n",
    "celebrity_unique.to_sql('celebrity', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6095a385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Load season table\n",
    "season_info_df = season_info_df[['season_number', 'premiere_date', 'finale_date', 'premiere_views', 'finale_views', 'num_of_episodes']].copy()\n",
    "\n",
    "# Drop duplicates (to handle returnees from earlier seasons)\n",
    "season_unique = season_info_df[['season_number', 'premiere_date', 'finale_date', 'premiere_views', 'finale_views', 'num_of_episodes']].drop_duplicates()\n",
    "\n",
    "#print(season_unique)\n",
    "season_unique.to_sql('season', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "926deb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Load pros table\n",
    "pros_unique_df = celeb_info_df[['ballroom_partner']].drop_duplicates()\n",
    "pros_unique_df.columns = ['pro_name']\n",
    "pros_unique_df.to_sql('pros', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aca0fbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "407"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Load celebrity_season table\n",
    "celebs = pd.read_sql('SELECT * FROM celebrity', engine)\n",
    "seasons = pd.read_sql('SELECT * FROM season', engine)\n",
    "pros = pd.read_sql('SELECT * FROM pros', engine)\n",
    "\n",
    "# Joining celebrity info and season info\n",
    "merged_celeb_season_df = pd.merge(celeb_info_df, celebs, on=['celebrity_name', 'celebrity_industry', 'celebrity_homestate', 'celebrity_homecountry'], how='left')\n",
    "\n",
    "merged_celeb_season_df = pd.merge(merged_celeb_season_df, seasons, left_on='season', right_on='season_number', how='left')\n",
    "\n",
    "merged_celeb_season_df = pd.merge(merged_celeb_season_df, pros, left_on='ballroom_partner', right_on='pro_name', how='left')\n",
    "\n",
    "celebrity_season_df = merged_celeb_season_df[['celebrity_id', 'season_id', 'pro_id', 'results', 'placement']].copy()\n",
    "celebrity_season_df.columns = ['celebrity_id', 'season_id', 'pro_id', 'result', 'placement']\n",
    "\n",
    "celebrity_season_df.to_sql('celebrity_season', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd0f3e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Load judges info table\n",
    "pros_unique_df = judges_df[['judge_name']].drop_duplicates()\n",
    "pros_unique_df.columns = ['judge_name']\n",
    "pros_unique_df.to_sql('judges', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52fee00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Load scores table\n",
    "celebrity_season = pd.read_sql('SELECT * FROM celebrity_season', engine)\n",
    "\n",
    "merged_df = pd.merge(celeb_info_df, celebs, on=['celebrity_name', 'celebrity_industry', 'celebrity_homestate', 'celebrity_homecountry'], how='left')\n",
    "\n",
    "merged_df = pd.merge(merged_df, judges_scores_df, on=['celebrity_name', 'season'], how='left')\n",
    "\n",
    "merged_df = pd.merge(merged_df, seasons, left_on='season', right_on='season_number', how='inner')\n",
    "\n",
    "merged_df = pd.merge(merged_df, pros, left_on='ballroom_partner', right_on='pro_name', how='inner')\n",
    "\n",
    "# Restructuring the judge's score tables by pivoting the week number to it's own column\n",
    "scores = []\n",
    "for week in range(1, 12):\n",
    "    week_cols = [f'week{week}_judge1_score', f'week{week}_judge2_score', f'week{week}_judge3_score',\n",
    "                 f'week{week}_judge4_score', f'week{week}_total_judge_score']\n",
    "    if all(col in merged_df.columns for col in week_cols):\n",
    "        temp_df = merged_df[['celebrity_id', 'season_id'] + week_cols].copy()\n",
    "        temp_df['week'] = week\n",
    "        temp_df = pd.merge(temp_df, celebs[['celebrity_id']], on='celebrity_id')\n",
    "        temp_df = pd.merge(temp_df, seasons[['season_id']], on='season_id')\n",
    "        temp_df['celebrity_season_id'] = pd.read_sql(\n",
    "            f'''\n",
    "            SELECT cs.celebrity_season_id\n",
    "            FROM celebrity_season cs\n",
    "            JOIN celebrity c ON cs.celebrity_id = c.celebrity_id\n",
    "            JOIN season s ON cs.season_id = s.season_id\n",
    "            ORDER BY cs.celebrity_season_id\n",
    "            ''', engine\n",
    "        )['celebrity_season_id'] \n",
    "\n",
    "        temp_df.rename(columns={\n",
    "            f'week{week}_judge1_score': 'judge1_score',\n",
    "            f'week{week}_judge2_score': 'judge2_score',\n",
    "            f'week{week}_judge3_score': 'judge3_score',\n",
    "            f'week{week}_judge4_score': 'judge4_score',\n",
    "            f'week{week}_total_judge_score': 'total_score'\n",
    "        }, inplace=True)\n",
    "        scores.append(temp_df[['celebrity_season_id', 'week', 'judge1_score', 'judge2_score', 'judge3_score', 'judge4_score', 'total_score']])\n",
    "\n",
    "\n",
    "# Concatenate all score data and load\n",
    "all_scores_df = pd.concat(scores)\n",
    "\n",
    "# Drop scores when judge 1-4 and total score is null (meaning they didn't make it to that week)\n",
    "all_scores_df = all_scores_df.dropna(\n",
    "    subset=['judge1_score', 'judge2_score', 'judge3_score', 'judge4_score'],\n",
    "    how='all'\n",
    ")\n",
    "\n",
    "new_score = all_scores_df[['celebrity_season_id', 'week', 'judge1_score', 'judge2_score', 'judge3_score', 'judge4_score']].copy()\n",
    "new_score.columns = ['celebrity_season_id', 'week', 'judge1_score', 'judge2_score', 'judge3_score', 'judge4_score']\n",
    "\n",
    "\n",
    "#print(new_score)\n",
    "new_score.to_sql('score', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e50e32f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7: load judges scores table\n",
    "score = pd.read_sql('SELECT * FROM score', engine)\n",
    "celebrity_season = pd.read_sql('SELECT * FROM celebrity_season', engine)\n",
    "\n",
    "judge_scores_long = pd.melt(\n",
    "    score,\n",
    "    id_vars=['score_id', 'celebrity_season_id', 'week'],  # columns to keep\n",
    "    value_vars=['judge1_score', 'judge2_score', 'judge3_score', 'judge4_score'],  # columns to pivot\n",
    "    var_name='judge_position',  # name for the new column holding judge positions\n",
    "    value_name='score'  # name for the values (scores)\n",
    ")\n",
    "\n",
    "# Drop null values\n",
    "judge_scores_long = judge_scores_long.dropna(subset=['score'])\n",
    "\n",
    "updated_judges_scores_df = pd.merge(judge_scores_long, celebrity_season, on=['celebrity_season_id'], how='left')\n",
    "\n",
    "updated_judges_scores_df = pd.merge(updated_judges_scores_df, seasons, on=['season_id'], how='left')\n",
    "\n",
    "merged_season_score = updated_judges_scores_df[['score_id','celebrity_season_id', 'week', 'judge_position', 'score', 'celebrity_id', 'season_id', 'pro_id', 'season_number']].copy()\n",
    "merged_season_score.columns = ['score_id','celebrity_season_id', 'week', 'judge_position', 'score', 'celebrity_id', 'season_id', 'pro_id', 'season_number']\n",
    "\n",
    "merged_season_score = pd.merge(merged_season_score, seasons, on=['season_id'], how='inner')\n",
    "\n",
    "# Dropping the repeated season_number column\n",
    "merged_season_score.rename(columns={'season_number_x': 'season'}, inplace=True)\n",
    "merged_season_score.drop(columns=['season_number_y'], inplace=True)\n",
    "\n",
    "# Merging with judges excel sheet\n",
    "merged_season_score = pd.merge(merged_season_score, judges_df, left_on=['season', 'judge_position'], right_on=['season', 'judge_position'], how='inner')\n",
    "\n",
    "merged_season_score = pd.merge(merged_season_score, judges_df, on=['season', 'judge_position', 'judge_name' ], how='inner')\n",
    "\n",
    "# Prepare to join the judges SQL table to get the judge_id\n",
    "judges = pd.read_sql('SELECT * FROM judges', engine)\n",
    "merged_season_score = pd.merge(merged_season_score, judges, on=['judge_name'], how='inner')\n",
    "\n",
    "merged_season_score = merged_season_score[['celebrity_season_id', 'judge_id', 'score_id', 'score']]\n",
    "\n",
    "merged_season_score.to_sql('judges_score', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6b298ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 8: Load dance_styles table\n",
    "dance_df = pd.read_excel(excel_path, sheet_name=\"dance_styles\")\n",
    "\n",
    "# Step 2: Get unique dance styles\n",
    "unique_dances = pd.DataFrame(dance_df['dance_style'].dropna().unique(), columns=['dance_name'])\n",
    "\n",
    "# Step 6: Insert the unique dances & Save to database\n",
    "unique_dances.to_sql(\"dance_styles\", engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc8f1c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 9:Load dances_performed table\n",
    "\n",
    "# Merging data to get what dances the celeb did each week for a particular season\n",
    "dance_df = dance_styles_df.merge( celebs, on='celebrity_name', how='left')\n",
    "\n",
    "dance_df = pd.merge(dance_df, seasons, left_on='season', right_on='season_number', how='left')\n",
    "\n",
    "dance_df = pd.merge(dance_df, pd.read_sql('SELECT * FROM celebrity_season', engine), on=['celebrity_id', 'season_id'], how='left')\n",
    "\n",
    "dance_df = pd.merge(dance_df, pd.read_sql('SELECT * FROM dance_styles', engine), left_on=['dance_style'], right_on=['dance_name'], how='left')\n",
    "\n",
    "dance_table = dance_df[['celebrity_season_id', 'dance_id', 'week']]\n",
    "\n",
    "#print(dance_df)\n",
    "dance_table.to_sql('dances_performed', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcf1959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 10: Unique hosts table\n",
    "# Step 5: Load judges info table\n",
    "hosts_unique_df = hosts_df[['hosts']].drop_duplicates()\n",
    "hosts_unique_df.columns = ['host_name']\n",
    "hosts_unique_df.to_sql('hosts', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b3d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 11: Host seasons table\n",
    "hosts = pd.read_sql(\"SELECT host_id, host_name FROM hosts\", engine)\n",
    "seasons = pd.read_sql('SELECT * FROM season', engine)\n",
    "\n",
    "merged_host_season_df = pd.merge(hosts_df, hosts, left_on = 'hosts', right_on='host_name', how='inner')\n",
    "\n",
    "merged_host_season_df = pd.merge(merged_host_season_df, seasons, left_on='season', right_on='season_number', how='inner')\n",
    "\n",
    "host_season_df = merged_host_season_df[['host_id', 'season_id']].copy()\n",
    "host_season_df.columns = ['host_id', 'season_id']\n",
    "\n",
    "host_season_df.to_sql('host_season', engine, if_exists='append', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
